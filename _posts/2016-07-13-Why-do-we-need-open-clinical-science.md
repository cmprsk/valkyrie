---
layout: post
comments: true
title:  "Why do we need open clinical science"
date:   2016-07-13 16:03:45 -0300
categories: valquiria
ref: open
lang: en
permalink: /open-clinical-science/
doi: 10.6084/m9.figshare.5435968
tags: clinical research, open science, open clinical science, open data, reproducible research, open notebook science
---
## More transparency in clinical research

The reasons why [clinical research][clnrs] is done should be obvious. However, one must address them and try to summarize them into a few working principles if an in depth analysis is to be carried out. It is probably a consensus that clinical research aims to develop new treatments for ailments. That said, it should be a corollary that clinical research seeks the benefit of the public. Additionally, it is paramount to clinical research the protection of the experimental subject.
In other words, the individuals that participate in clinical research must not be submitted to unethical or inhumane conditions or procedures, and this includes their privacy. A third principle could be stated as follows: clinical research must adhere to a rigid methodology in order to ensure the highest possible likelihood of reliability of the results. Methodology and reporting have to be clear enough so these results may be fully reproducible by third parties. This will guarantee that the resources spent in the research are not wasted in futile efforts.

This leads us to a set of three principles one could summarize as goes:

1. Uphold the interest of the public.
2. Protect the integrity of the participant.
3. Follow a strict, reproducible method.

What is the best way to ascertain that all clinical research will adopt these principles to the heart? The answer is very difficult, and no one has ever succeeded completely in this intent, as far as I know. A series of reasons complicates the prospect of clinical research, but the most important seem to be conflicts of interest from funders and scientists. However, one may not underestimate the influence of widespread cultural beliefs of science makers and the general public and a pervasive unfamiliarity with the meaning and shortcomings of statistical methods. These are not really small problems. The net result of the clinical research difficulties are low probability of publication of final results of clinical trials (even when they are clinically meaningful), and overall lack of transparency of information derived from clinical trials.

How to revert this situation? There are many initiatives and propositions that try to address this problem. Briefly, one can divide them in two wide sets or groups: weak (conservative) reform models or strong (non-conservative) reform models. Both aim the same thing: optimize the information productive chain in clinical research. Information can be viewed as an asset, the most important one in this kind of model. The problem can be stated as one of inefficient utilization of this asset. Conservative models generally do not propose major changes in the way information is generated and monetized, but try to effect a discipline upon the agents of this production chain. One can have property of information, but will have to conform to a series of good practices. These practices include mostly registering the clinical research (trial) and its results. Non-conservative models, on the contrary, defy the paradigm of information generation, monetization and ownership. They are based on the idea that information is a property of all people. These models argue against ownership of information by individuals or collectives, and advocate the widespread use of open publication of information in the world wide web.

A good example of conservative initiatives are the legislation of many countries that specificaly asks the registering of any and all clinical trials. Brazil is an example of this kind of regulation. Prior to the approval of any clinical research by an Institutional Review Board, it has to be registered in Plataforma Brasil, a centralized registry for any clinical or pre-clinical research project in the country, maintained by the Ministry of Health. However, there is little (if at all) enforcement of the law in Brasil, and a great number of clinical research projects that are registered ends up never reporting if it was concluded or have any results. This is far from ideal. An international, independent initiative that can be grouped in the conservative tier is Ben Goldacre's [AllTrials.net][alltrls], a non-governamental organization of leading science editorial groups and many others devoted to spread the message: "all trials registered, all results published". The common point of conservative-type models is that the axis of pharma business funding, science editorial traditional business and ivy league institutions with business-tied research activity is not even mentioned, let alone questioned.

Notwithstanding that, virtually all "first-tier" scientific publications are produced in this mainstream information productive chain. They are funded by big pharma, carried out by selected highly regarded institutions and reported in the most traditional and difficult to publish scientific journals. As a correlate measure of influence of this axis, we can examine the distribution of the Thomson Reuters Impact Factor. Less than 0.1% of 2014 published papers were really highly cited, a fact that shapes the landscape of impact factor distribution and, consequently, the rank of the most prestigious journals. That highly redundant, positive feedback loop system concentrates the majority of important clinical research. As a logical conclusion, one can state that most problems with clinical science transparency arise in this axis.

This perception has fueled non-conservative initiatives that aim at this very central structure of clinical research. In the last few years, these largely independent and loosely related programs have coalesced in the concept of Open Science. The conceptualization of Open Science has evolved from an analogy to open source software and into a complex idea mainly based on information transparency.

## What is Open Science?

![taxonomy](https://s3-eu-west-1.amazonaws.com/pfigshare-u-previews/2250225/preview.jpg)

According to the [Foster (Facilitate Open Science Training for European Research)][fstr] initiative site, open science is ```an umbrella term that involves various movements aiming to remove the barriers for sharing any kind of output, resources, methods or tools, at any stage of the research process``` ([Knoth, 2015][txnmy]). Such a concept is open and evolving, and aggregates the free sharing of science production as a whole, encompassing all its multiple phases. From the benchside to the final applications. It's far outstreaching than conceptually narrower conservative initiatives. Even though most of the focus remains on Open Data and Open Access publication, OS is far more than this.

The [OECD (Organization for Economic Cooperation and Development)][oecd] states that Open Science is ```to make the primary outputs of publicly funded research results – publications and the research data – publicly accessible in digital format with no or minimal restriction``` ([OECD, 2015][oecd15]). Notwithstanding this, its outreach is much wider, and extends to the whole science production cycle ([Fuente, 2016][fnt]).

![cycle](https://www.fosteropenscience.eu/sites/default/files/images/OpenScienceResearchInitiative-ResearchLifecycle.png)

The basic concept behind Open Science is that of spreading the scientific knowledge. Actually, this idea can be traced back to the Ancient Library of Alexandria, whose main purpose was to collect all the world's knowledge at its time, under the patronage of the ruler of macedonian Egypt. Although the beginning of _open science_ as a conceptual framework has been traditionally ascribed to the birth of academic journals in 17th century, the idea of disseminating knowledge is clearly of very ancient origin in ocidental tradition. One of its predecessors may have been the teachings of Aristotle at Athens's Lyceum in the 4th century BC. He introduced the notion of cooperative research and systematic collection of empiric observations (Lindberg, 1992).

Notwithstanding the breakthrough brought by the invention of the press in XV century and the academic journals in the XVII century, only in the 40s did the sociologist Robert King Merton clearly defined the notion of common ownership of scientific discoveries. In his view, science achievements are a product of social collaborarion and must be assigned to the community. The system of peer-review and subscription-based scholarly publications that has long been the standard, has been shaken recently. The development of digital tools of information and communication technologies has introduced a new disruptive element in the scientific productive cycle. In a 2009 essay ([Massing, 2009][massing]), journalist Michael Massing has refered to the analogy between the introduction of the printing press and the advent of the internet (attibuted to NYU's Clay Shirsky):

> The historical analogy can be taken a step further: just as the advent of printing helped break the medieval Church’s hold on the flow of information, so is the rise of the Internet loosening the grip of the corporate-owned mass media. A profound if unsettling process of decentralization and democratization is taking place.

The term **Open Science** would be introduced in 2003 by the economist Paul David. trying to analyse the relation between the scientific production by the public sector and the rise of intellectual property rights of information assets. Although still a loosely defined concept with multiply interpretations, the Open Science movement has gained momentum all over the world, and policy makers and researchers are talking about it.

## What about open clinical science?

The logical product of the direct application of open science tenets to clinical research would be something like _open clinical science_. Is there anything like open science in clinical research at all? Actually, there is.

Cardiologist [Harlan Krumholz][hk], better known for his endless crusade for point-of-care quality and patient-oriented outcomes that reshaped modern medicine, is probably one of the pioneers of _open science_ in clinical research, or what we could really call **open clinical science**. Studying unpublished data obtained from litigation, he could show that Merck had data proving Vioxx (rofecoxib) to raise cardiovascular deaths way before it was withdrawn from the market. Cases like this led him and many others that followed to propose the disclosure of all clinical data in public databases, much like the central tenet of _open science_. Dr Krumholz has put forward a set of rules ('steps' as he worded) that the minimal to 'to bring data sharing and open science into the mainstream of clinical research' ([Krumholz, 2012][steps]):

1. Post, in the public domain, the study protocol for each published trial. The protocol should be comprehensive and include policies and procedures relevant to actions taken in the trial.
2. Develop mechanisms for those who own trial data to share their raw data and individual patient data.
3. Encourage industry to commit to place all its clinical research data relevant to approved products in the public domain. This action would acknowledge that the privilege of selling products is accompanied by a responsibility to share all the clinical research data relevant to the products' benefits and harms.
4. Develop a culture within academics that values data sharing and open science. After a period in which the original investigators can complete their funded studies, the data should be de-identified and made available for investigators globally.
5. Identify, within all systematic reviews, trials that are not published, using sources such as clinicaltrials.gov and regulatory postings to determine what is missing.
6. Share data.

The importance of sharing all clinical data must be adequately stressed. Data ([Chen, 2016][bmj1]) show that less than half of all clinical trials are published up to 2 years from their completion, and this includes those with public funding. Trials with negative results are less likely to be published as well. A study has demonstrated that almost all meta-analyses they examined would have their conclusions affected by unpublished data. Even though the focus has been on high methodological quality standards for clinical trials, no elegant method can compensate for missing data, as Dr Krumholz states. A recent systematic review ([Fleetcroft, 2015][sysrev]) of heart failure was hampered because of poor reporting and non-disclosure of data, although the pivotal clinical studies had already been done. An attempt to review ([Ebrahim, 2014][rerct]) reanalyses of randomized controled trials has led to the disturbing conclusion that they are exceedingly rare and methodologically flawed, nevertheless suggesting that the original trials results could lead to different conclusions. Science is based upon the very possibility of hypotheses test and re-test, but this seems not to be the rule in clinical science.

A survey ([Rathi, 2012][bmj2]) among clinical trialists has shown strong support to share de-identified data. However, the community raised a number of concerns: how to ensure appropriate data use, protection of investigator or funder interests, and protection of research subjects. This suggests that the academic community is ready for _open clinical science_ but demands a proper platform to lead it safely for all parties involved. Such a platform may already been born in the Yale University Open Data Access (YODA) project, that published ([Krumholz, 2013][yoda]) its first patient-level open clinical data comprehensive reports in 2013. The oldest institutional patient-level data sharing policy may be that from the National Heart, Lung, and Blood Institute (NHLBI) ([Coady, 2013][nhlbi]), which repository has data on more than 560,000 participants from 100 clinical trials and observational studies held since 1989. Its policy evolved with time, and set a number of limitations on the sharing and utilization of patient data, making it not truly open access. Many doubt, however, that _true open science_ is feasible in clinical science ([Flather, 2015][flather]).

## Conclusion

Nevertheless the critics and the skeptical, it has became evident that we need a better clinical science to guide bedside clinical decisions. It is not a question of the feasibility of it, it is more of when we are going to implement _open clinical science_ for the better.

## Links:

- [Clinical research, Wikipedia][clnrs]
- [AllTrials.net][alltrls]
- [Facilitate Open Science Training for European Research, FOSTER][fstr]
- [Organization for Economic Cooperation and Development, OECD][oecd]
- [Harper, Matthew. The most powerful doctor you never heard of. Forbes, 09/09/2010][hk]

## References:

1. [Knoth, Petr; Pontika, Nancy (2015): Open Science Taxonomy. figshare.][txnmy]
2. [OECD (2015), “Making Open Science a Reality”, OECD Science, Technology and Industry Policy Papers, No. 25, OECD Publishing, Paris][oecd15]
3. Gemma Bueno de la Fuente. What is open science? Introduction. [webpage][fnt], retrieved in 10/15/2016.
4. Promoting openness at different stages of the research process (figure). Open Science and Research Initiative (2014). Open Science and Research Handbook. [English version] Available at [webpage][oshndbk]
5. Lindberg, David C. (2007) [1992]. "4: Hellenistic Natural Philosophy". The Beginnings of Western Science (2nd ed.). Chicago: University of Chicago Press. ISBN 0-226-48205-7.
6. [Massing, Michael. The news about the internet. The New York Review of Books, August 13, 2009.][massing]
7. [Krumholz, HM. Open Science and Data Sharing in Clinical Research Basing Informed Decisions on the Totality of the Evidence. Circulation: Cardiovascular Quality and Outcomes. 2012;5:141-142][steps]
8. [Chen, R _et al_. Publication and reporting of clinical trial results: cross sectional analysis across academic medical centers. BMJ 2016; 352 doi:10.1136/bmj.i637][bmj1]
9. [Fleetcroft, R _et al_. Difficulty accessing data from randomised trials of drugs for heart failure: a call for action. BMJ 2015; 351 doi:10.1136/bmj.h5002][sysrev]
10. [Ebrahim  S, Sohani  ZN, Montoya  L,  et al.  Reanalyses of randomized clinical trial data.  JAMA 2014 doi:10.1001/jama.2014.9646][rerct]
11. [Rathi, V _et al_. Sharing of clinical trial data among trialists: a cross sectional survey. BMJ 2012; 345 doi:10.1136/bmj.e7570][bmj2]
12. [Krumholz, HM _et al_. A Historic Moment for Open Science: The Yale University Open Data Access Project and Medtronic. Ann Intern Med. 2013;158(12):910-911 doi: 10.7326/0003-4819-158-12-201306180-00009][yoda]
13. [Coady, SA & Wagner E. Sharing individual level data from observational studies and clinical trials: a perspective from NHLBI. Trials 2013 14:201 doi:10.1186/1745-6215-14-201][nhlbi]
14. [Flather, M. Open access data sharing from clinical trials: is it really feasible? Eur Heart J - Qual Care Clin Outcomes, 2015 1(2):49–50, doi:10.1093/ehjqcco/qcv019][flather]

[clnrs]: https://en.m.wikipedia.org/wiki/Clinical_research
[alltrls]: http://alltrials.net
[fstr]: https://www.fosteropenscience.eu
[oecd]: http://OECD.org
[oecd15]: http://dx.doi.org/10.1787/5jrs2f963zs1-en
[fnt]: https://www.fosteropenscience.eu/content/what-open-science-introduction
[oshndbk]: https://avointiede.fi/documents/14273/0/Open+Science+and+Research+Handbook+v.1.0/50316d5d-440b-4496-b039-2997663afff8
[txnmy]: https://dx.doi.org/10.6084/m9.figshare.1508606.v3
[jekyll]: https://jekyllrb.com
[jekyll-twitter-plugin]: https://github.com/rob-murray/jekyll-twitter-plugin
[murray]: https://github.com/rob-murray
[massing]: http://www.nybooks.com/articles/2009/08/13/the-news-about-the-internet/
[hk]: https://www.forbes.com/forbes/2010/0927/opinions-harlan-krumholz-yale-medicine-ideas-opinions.html
[steps]: https://doi.org/10.1161/CIRCOUTCOMES.112.965848
[bmj1]: https://doi.org/10.1136/bmj.i637
[sysrev]: https://doi.org/10.1136/bmj.h5002
[rerct]: https://doi.org/10.1001/jama.2014.9646
[bmj2]: https://doi.org/10.1136/bmj.e7570
[yoda]: https://doi.org/10.7326/0003-4819-158-12-201306180-00009
[nhlbi]: https://doi.org/10.1186/1745-6215-14-201
[flather]: https://doi.org/10.1093/ehjqcco/qcv019
